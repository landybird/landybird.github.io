---
title: 面试题
description: 面试相关
categories:
- 面试准备
tags:
- 面试准备
---

<br>






#### 递归遍历所有的 文件夹和文件


```python

from pathlib import Path

def print_directory_contents(s_path):
    path = Path(s_path)
    for child in path.iterdir():
        if child.is_file():
            print(child.resolve())
        elif child.is_dir():
            print_directory_contents(child.resolve())

# 具体实现步骤如下：

    # 输入文件夹路径。
    # 将路径转换成Path对象。
    # 使用Path.iterdir()函数获取该文件夹中所有文件和文件夹的名称。
    # 遍历列表中的每一个子项。
    # 如果该路径是一个文件，打印该文件的绝对路径。
    # 如果该路径是一个文件夹，递归调用自身，传入该路径。
    
# 需要注意的是，Path库是从Python 3.4版本开始引入的，如果是旧版本的Python，需要使用os模块来操作文件和文件夹。

import os

def print_directory_contents(s_path):
    for s_child in os.listdir(s_path):
        s_child_path = os.path.join(s_path, s_child)
        if os.path.isdir(s_child_path):
            print_directory_contents(s_child_path)
        else:
            print(s_child_path)
```


#### 输入日期， 判断这一天是这一年的第几天


```python
import datetime

def day_of_year(date):
    year_beginning = datetime.datetime(date.year, 1, 1)
    delta = date - year_beginning
    return delta.days + 1
```


#### 打乱一个排好序的list对象

```python
import random

my_list = [1, 2, 3, 4, 5]

#打乱列表
random.shuffle(my_list)

print(my_list)

# 该函数会直接修改原列表，因此请确保您已经备份好了需要打乱顺序的原始列表
```


#### 字典按value值进行排序


```python
# 方案一：使用sorted()函数和lambda表达式

my_dict = {'apple': 5, 'banana': 3, 'orange': 2, 'pear': 1}

# 使用sorted()函数和lambda表达式按照value排序
sorted_dict = sorted(my_dict, key=lambda x: x[1])

print(sorted_dict)
# 输出结果：
# 
# {'pear': 1, 'orange': 2, 'banana': 3, 'apple': 5}



# 方案二：使用operator模块的itemgetter()函数
import operator

my_dict = {'apple': 5, 'banana': 3, 'orange': 2, 'pear': 1}

# 使用itemgetter()函数按照value排序
sorted_dict = dict(sorted(my_dict.items(), key=operator.itemgetter(1)))

print(sorted_dict)
# 输出结果：
# 
# {'pear': 1, 'orange': 2, 'banana': 3, 'apple': 5}

```


#### 字典设置默认值 `defaultdict`


`defaultdict` 是 Python 内置字典类（dict）的一个子类，它重载了一个方法并添加了一个可写的实例变量。

    `defaultdict` 类允许给定的默认类型作为工厂函数，这样不存在的键就返回这个默认类型对应的初始值

    dict_by_sale_email = defaultdict(list)


下面是 `defaultdict` 的几种应用场景：


- 字典初始化：使用 `defaultdict` 可以对一个字典在初始化时就设定所有不存在的键的默认值，可以让代码更简洁明了，例如：

```python
from collections import defaultdict

person = defaultdict(int)  # 所有未定义的键将获得 int 对应的空值
person['age'] += 1
person['age'] += 1
person['age'] += 1
print(person['age'])  # 这将输出 3，因为 age 变量初值为 0

```


- 分组累加：在从其它数据源聚合数据时，可以使用 `defaultdict` 对数据进行分组并累加得到最终结果，例如统计字符串中单词出现的次数：

```python
from collections import defaultdict

s = "the quick brown fox jumps over the lazy dog"
words = s.split()
word_count = defaultdict(int)

for word in words:
    word_count[word] += 1

print(word_count)  # 会输出一个字典，其中单词和对应的次数都被打印出来
```

- 处理缺失值：在数据处理过程中，有些数据可能会出现缺失的情况，可以使用 defaultdict 在初始值为 None 或 0 的情况下进行处理，例如：

```python
from collections import defaultdict

data = [
    {"name": "张三", "age": 18},
    {"name": "李四", "age": 20},
    {"name": "王五"}
]
people = defaultdict(lambda: {"name": None, "age": 0})

for person in data:
    people[person["name"]]["name"] = person["name"]
    if "age" in person:
        people[person["name"]]["age"] = person["age"]

print(dict(people))  # 会输出一个字典，其中缺失 age 的数据将被填充为 0
```

总之，`defaultdict` 主要用于`创建默认值非空的字典`、`统计频数`以及`分组累加`等场景，可以简化代码实现和提高代码可读性。



#### 列表切片操作不会抛出`IndexError`异常

因为列表切片操作不会抛出`IndexError`异常。如果切片结束位置超出了列表的长度，则返回一个空列表。此时，切片索引不合法，但不会导致程序异常。

```python
l = ['a','b','c','d','e']
print(l[10:]) 

# []
```
    
    
    列表切片的实现机制是在底层使用了C语言实现，具体实现原理如下：
    
        对列表进行切片操作时，会从列表的头部或尾部偏移切片索引，并以切片步长为间隔，提取需要的元素，组成一个新的列表。
        
        如果切片的起始位置和结束位置都没有超出列表长度，则直接从内存中按照索引提取元素，返回一个新的列表。
        
        如果切片的结束位置超出了列表长度，则会在新的列表中只提取列表中存在的元素，如果列表中不存在对应的元素，则返回一个空列表。
        
        如果切片的起始位置超出了列表长度，则返回一个空列表。
    
    在所有情况下，切片操作都不会修改原有列表，而是返回一个新的列表。



#### 给定两个列表，怎么找出他们相同的元素和不同的元素



```python
list1 = [1, 2, 3, 4, 5]
list2 = [3, 4, 5, 6, 7]

set1 = set(list1)
set2 = set(list2)

print(set1 & set2)
# {3, 4, 5}
print(set1 ^ set2)
# {1, 2, 6, 7}
print(set1 | set2)
# {1, 2, 3, 4, 5, 6, 7}

```



#### python新式类和经典类的区别？


在 `Python2` 中，有`新式类`和`经典类`的区别

在 `Python3` 中默认只有一种类型的类，即都是`新式类`。


下面是它们的区别：

- 1 `经典类`不继承 `object`，`新式类`继承 `object`

在 Python3 中所有类默认继承 object，而在 Python2 中，如果一个类没有显式地继承自 object 或其子类，那么这个类就是一个经典类。在 Python2 中，如果你需要使用新式类的特性，必须显式地指定该类继承自 object 或它的子类，例如：

```python
class MyClass(object):
    pass
```

- 2 `方法解析顺序(Method Resolution Order，MRO)`不同

`经典类`的属性查找方式是按照`从子类到父类`的顺序进行搜索

`新式类`在搜索属性时，会按照一个特定的算法`（C3算法）`在类的继承层次结构中进行搜索，该算法确保所有基类的属性仅被访问一次，且按照正确的顺序进行搜索。



- 3 `多继承的 MRO `不同

在多继承情况下

`新式类`的 `MRO 算法`确保每个基类仅被访问一次，且按照正确的线性顺序进行访问

`经典类`则是`深度优先`的搜索方式。

这就导致，当继承树中存在钻石继承时，新式类不会出现属性查找顺序的歧义，而经典类则可能导致与预期不符的结果。


- 4  `内置函数 type` 的行为不同

在 `Python2` 中，当使用 `type 函数`创建一个类时，如果它继承自经典类（没有显式地继承自 object），那么它的一些特性与新式类是不同的。

在 `Python3` 中，所有类都经过优化，使得 `type`创建的类与通过 class 关键字定义的类没有区别。


总结来说，Python2 中的新式类比经典类功能更强大，具有更多的特性，同时也修复了一些经典类存在的问题；
而 Python3 的默认统一采用新式类，避免了这些问题。


#### Python 3 中有以下几种内置数据结构类型：
    
    列表（List）：可变序列，元素可以是任何类型。
    元组（Tuple）：不可变序列，元素可以是任何类型。
    集合（Set）：无序，不重复的集合，支持交、并、差等基本操作。
    字典（Dictionary）：键-值对映射的散列表，键和值都可以是任何类型。
    字符串（String）：不可变序列，字符串是字符的集合。
    此外，Python 3 中还有一些其他内置类型，例如布尔型（bool）、整型（int）、浮点型（float）、复数型（complex）等。这些类型是基础类型，用于表示程序的基本数据。
    
    
    Python 3 中内置的数字类型有整型（int）、浮点型（float）和复数型（complex）。
        
        整型（int）：用于表示整数，Python 3 中的整型是任意精度的整数，可以表示任意大小的整数，不受位数限制。
        
        浮点型（float）：用于表示浮点数，即小数。Python 3 中的浮点型采用 IEEE754 标准，支持无限大、NaN、正负零等特殊值，可表示的精度是 10^-16 级别。
        
        复数型（complex）：用于表示复数，即有实部和虚部的数。Python 3 中的复数型支持常规的加、减、乘、除等算术操作，也支持求模、求共轭等操作。
    
    这些数字类型之间的区别主要在于所能表示的数据范围、精度和支持的操作等方面。在使用时需要根据实际需要选择合适的数据类型。
    如果数据量很大或需要高精度的计算，可以选择整型；如果需要使用小数或浮点数，可以选择浮点型；如果需要表示复数，可以选择复数型。


#### python如何实现`单例模式`?请写出两种实现方式?


```python
from functools import wraps

# 1 装饰器
def singleton(mcs):
    instance = {}

    @wraps(mcs)
    def get_instance(*args, **kw):
        if mcs not in instance:
            instance[mcs] = mcs(*args, **kw)
        return instance[mcs]
    return get_instance


# 元类创建
class SingletonClass(type):
    _instance = {}

    def __call__(mcs, *args, **kw):
        if mcs not in mcs._instance:
            mcs._instance[mcs] = super(SingletonClass, mcs).__call__(*args, **kw)
        return mcs._instance[mcs]


# 3 类初始化
class SingleParentClass:
    _instance = {}

    def __new__(mcs, *args, **kwargs):
        if mcs not in mcs._instance:
            mcs._instance[mcs] = super(SingleParentClass, mcs).__new__(mcs, *args, **kwargs)
        return mcs._instance[mcs]


@singleton
class A:
    ...


class B(metaclass=SingletonClass):
    ...


class C(SingleParentClass):
    ...


a = A()

b = A()

print(a == b)

# True


c = B()
d = B()

print(c == d)
# True


f = C()

m = C()

print(f == m)
# True

```

#### 元类的执行过程

```python
class MetaF(type):
    def __init__(cls, *args, **kw):
        print(f"MetaF __init__")
        super(MetaF, cls).__init__(*args, **kw)

    def __call__(cls, *args, **kwargs):
        print(f"MetaF __call__")
        return super(MetaF, cls).__call__(*args, **kwargs)

    def __new__(mcs, *args, **kwargs):
        print(f"MetaF __new__")
        return super(MetaF, mcs).__new__(mcs, *args, **kwargs)


# 也就是  class = MetaF("F", (), {})
class F(metaclass=MetaF):

    def __init__(self):
        print("F __init__")

    def __new__(cls, *args, **kwargs):
        print("F __new__")
        return super(F, cls).__new__(cls, *args, **kwargs)

    def __call__(self, *args, **kwargs):
        print("F __call__")


        
# MetaF __new__
# MetaF __init__
# MetaF __call__
# F __new__
# F __init__
# F __call__

```
    
    class F(metaclass=MetaF):
        ...

        MetaF __new__       执行MetaClas(type)的 __new__ 方法(类是type的对象)
        MetaF __init__      执行MetaClas(type)的 __init__ 方法(类是type的对象)


    f = F()
        MetaF __call__      执行MetaClas(type)的 __call__ 方法(类是type的对象)
        F __new__
        F __init__

    f()
        F __call__          执行F的 __call__ 方法(f 是 F对象)


#### 反转数字 

```python

# 字符串切片
def reverse_number(number: int):
    tmp_str = str(number)
    if tmp_str[0] == "-":
        return int(f"-{tmp_str[:0:-1]}")
    return int(f"{tmp_str[::-1]}")

s = reverse_number(2312345)
print(s)
```


####  遍历修改列表 (删除元素)


```python

# 1 使用倒序(索引递减)， 避免索引超出范围


a = list(range(0, 9))

for i in range(len(a) - 1, -1, -1):
    if a[i] % 2 == 0:
        a.remove(a[i])

print(a)



# 2 利用 for ... else ..., 

# 每次删除元素后跳出遍历，直达删除全都

a = list(range(0, 9))


while 1:
    for i in a:
        if i % 2 == 0:
            a.remove(i)
            break
    else:
        break
        
print(a)
```


#### `is` 和 `==` 有什么区别？


    is：比较的是两个对象的id值是否相等，也就是比较俩对象是否为同一个实例对象。是否指向同一个内存地址
    
    == ： 比较的两个对象的内容/值是否相等，默认会调用对象的eq()方法



#### Python中`变量的作用域`


Python中变量的作用域分为`全局作用域`和`局部作用域`。


全局作用域：

    在程序的整个范围内都可以访问的变量，即全局变量。
    
    全局变量可以在程序的任何位置被访问和修改，包括函数内部和函数之外。在函数内部如果要修改全局变量的值，需要在函数内部使用 global 关键字声明。

示例代码：

```python
global_var = "Global"

def test_func():
    print(global_var)

test_func() # 输出 Global

def modify_func():
    global global_var
    global_var = "Modified Global"

modify_func()
print(global_var) # 输出 Modified Global

```

局部作用域：
    
    在函数内部定义的变量，只能在该函数内部被访问的变量，即局部变量。
    
    在函数外部无法访问局部变量，也不能在函数外部修改局部变量的值。

示例代码：


```python
def test_func():
    local_var = "Local"
    print(local_var)

test_func() # 输出 Local

print(local_var)  # 会报错，因为局部变量只能在函数内部访问
```

如果需要在函数中访问全局变量，可以使用 `global` 关键字将其声明为全局变量。



#### python 中 `变量的查找顺序`


Python 中变量的查找顺序由 `LEGB 规则`确定，即

    从内到外依次查找局部变量（Local）
    
    封闭函数中的变量（Enclosing）
    
    全局变量（Global）
    
    内置变量（Built-in）


如果在当前作用域内找不到变量，就会往外层作用域查找，直到找到为止。


也就是说，在嵌套的函数中，`内部函数可以访问外部函数的变量，而外部函数不能访问内部函数的变量`。


示例代码如下：

```python
global_var = "Global"

def outer_func():
    outer_var = "Outer"
    
    def inner_func():
        inner_var = "Inner"
        print(inner_var) # Inner
        print(outer_var) # Outer
        print(global_var) # Global
        
    inner_func()
    print(outer_var) # Outer

outer_func()

```

在上述代码中，

`global_var 是全局变量`，可以在任何位置访问；

`outer_var` 是外部变量，只能在外部函数和内部函数中访问；

`inner_var` 是内部变量，只能在内部函数中访问。

其中，`内部函数 inner_func` 可以访问全局变量、外部变量和内部变量，而`外部函数 outer_func` 只能访问全局变量和外部变量。


#### 字符串数字 转换成 数字 (`不使用内部API`)


根据 `ASCII 码`将其转换为数字

    0 到 9 这几个数字字符的 ASCII 码是连续的（48 到 57）

    根据位数进行乘法运算得到最终结果

```python
s = "123"
ans = 0
for c in s:
    ans = ans * 10 + ord(c) - ord('0')
    
print(ans) # 123
```



####  两个有序列表，l1,l2，对这两个列表进行合并 不使用extend
 

    
    可以使用循环来进行列表合并，具体步骤如下：
        
        建立一个新的空列表result来存储合并后的数据。
        
        通过两个指针i,j来分别指向l1和l2的第一个元素。
        
        循环遍历，比较i和j所指向的元素，将较小值加入result，同时指针向后移动一位。
        
        当其中一个列表被遍历完时，将另一个列表的剩余元素直接加入result。
        
        返回合并后的结果列表result。

```python
l1 = [1, 2, 3, 4, 5, 6]
l2 = [3, 4, 5, 6, 7, 8, 9, 10]


def merge_order_list(l_1, l_2):
    result = []

    i, j = 0, 0

    while i < len(l_1) and j < len(l_2):
        if l_1[i] < l_2[j]:
            result.append(l_1[i])
            i += 1
        else:
            result.append(l_2[j])
            j += 1
    
    # 超出边界
    if i == len(l_1):
        result += l_2[j:]
    else:
        result += l_1[i:]
```


#### 

```python
def multi():
    return [lambda x: i*x for i in range(4)]


for m in multi():
    print(m(3))
    
# 9
# 9
# 9
# 9
# 因为，最后函数被调用的时候，for循环已经完成, i 的值最后是3,因此每一个返回值的i都是3,所以最后的结果是[9,9,9,9]



# 生成器 遍历时候才声明
def multi_gen():
    return (lambda x: i*x for i in range(4))


for m in multi_gen():
    print(m(3))

# 0
# 3
# 6
# 9

```

#### `Cython，Jython, Pypy Cpython Numba`各有什么缺点

    
    Cython：
    
        需要编写Cython代码，具有一定的学习和编写成本。
        移植性相对较差，需要适配不同的操作系统和编译器。
    
    Jython：
    
        对于某些Python库或应用程序支持不完整或不稳定。
        性能相对较慢，尤其是在处理大量数据时。

    Pypy：
        
        优化的是Python的解释器，而不是源代码。
        不支持部分Python库的加速。
        在处理多线程和内存占用方面存在一些问题。

    CPython：
    
        解释器运行效率相对较慢，尤其在处理大量数据时。
        由于GIL的存在，多线程性能相对较差

    Numba：
    
        只适用于一些数值计算和科学计算领域，而并不支持所有Python库的加速。
        需要与NumPy或其他Cython或C库配合使用。
        可读性相对较差，代码可维护性相对较弱。

总的来说，这些库和解释器都有各自的优点和缺点。

`Cython`和`Numba`适用于科学计算和数值计算领域，但需要较高的编写和学习成本。
`Pypy`和`Jython`具有一定的跨平台性和代码可读性，但在性能和Python库的支持上存在一些问题。

`CPython`是Python语言的`默认解释器`，但在处理大量数据和多线程方面存在缺陷。


#### `抽象类`和`接口类`的区别和联系

在Python中，`抽象类和接口类`都是通过继承`abc.ABC`类来实现的


区别

    1) 接口类中只能定义抽象方法，而 抽象类中可以定义抽象方法和具体方法。

    2) 抽象类中可以定义抽象属性和具体属性，而接口类不能定义属性。

    3) 子类继承抽象类时可以选择实现抽象方法，也可以不实现，但继承接口类时必须实现接口中的所有抽象方法。

联系

    抽象类和接口类都是用于约束类的行为。

    抽象类和接口类都是不能被直接实例化的。


下面是一个抽象类和接口类的例子：

```python
import abc

# 抽象类
class Animal(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    # 抽象方法
    def talk(self):
        pass
    # 具体方法
    def run(self):
        print("Animal is running...")

class Dog(Animal):
    def talk(self):
        print("Dog is barking...")

d = Dog()
d.talk()  # Dog is barking...
d.run()   # Animal is running...

# 在这个例子中，Animal是一个抽象类，其中talk是一个抽象方法，run是一个具体方法。
# Dog通过继承Animal类，实现了talk方法，并继承了run方法。


# 接口类
class Shape(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def area(self):
        pass
    
    @abc.abstractmethod
    def perimeter(self):
        pass

class Circle(Shape):
    def __init__(self, r):
        self.r = r
        
    def area(self):
        return 3.14 * self.r * self.r
    
    def perimeter(self):
        return 2 * 3.14 * self.r

c = Circle(5)
print(c.area())       # 78.5
print(c.perimeter())  # 31.4


# Shape是一个接口类，其中area和perimeter都是抽象方法。
# Circle通过继承Shape类，实现了area和perimeter方法。

```

#### 哪些操作会导致Python内存溢出，怎么处理

Python`内存溢出`通常是由于程序分配了过多的内存，而Python没有及时释放内存导致的。


以下是一些可能导致Python内存溢出的操作：

    创建大量对象并保留对它们的引用，尤其是大对象。
    
    对已经创建的大型数据结构进行不必要的复制。

    递归调用过多层次或者发生死循环等。

    读取大量数据到内存中并在内存中保留数据。

    使用一些内存占用高的库或者模块，如一些科学计算库numpy、pandas等。

以下是一些处理Python内存溢出的方法：
    
    通过减少保留大型对象的引用，及时清理无用的对象。
    
    尽量避免不必要的复制，通过对大型数据进行迭代处理等方式，避免一次性将整个数据复制到内存中。
    
    对于递归调用层数过多的函数，可以考虑改写非递归方式实现。
    
    在读取大量数据时，可以适当增加硬件资源，如增加内存、优化硬盘寻址等策略。
    
    使用内存占用较低的库或模块，优化代码结构，避免内存泄漏等。
    
    利用Python的垃圾回收机制，在程序运行过程中自动回收无用的内存，可以避免一些内存泄漏问题。
    
    分析内存使用情况，借助一些工具如Python的 memprofile（第三方库）、heapy、pympler等对内存泄漏点进行分析和优化。

总之，避免Python内存溢出的关键在于优化程序设计，合理使用内存资源和规避一些可能导致内存泄漏的操作。 



#### Python的内存管理机制：
    
    引用计数：Python使用引用计数来追踪每个对象的引用次数。

        当一个对象被赋值给一个变量时，它的引用次数会增加；
        当这个变量被删除时，它的引用次数会减少。
        当一个对象的引用次数为0时，它将被自动删除。
            
    引用追踪：当一个对象的引用次数为0时，Python会将其从内存中删除。

        为了保证对象之间的正确性，Python在内部维护了一个链表，用于追踪每个对象的引用情况。
    
    循环引用处理：当两个对象互相引用时，如果仅使用引用计数，这两个对象的引用计数将永远不为0，导致内存泄漏。

        为了解决这个问题，Python使用了标记-清除算法和分代垃圾回收。


        
        Python的标记-清除算法和分代垃圾回收的实现如下：
        
        标记-清除算法
        标记-清除算法是一种基本的垃圾回收算法，它通过标记所有活动对象，在清除所有未被标记的非活动对象来回收内存空间。Python的垃圾回收机制会定期触发标记-清除算法，并使用两个标记，即可达标记和不可达标记，来确定哪些对象可以被回收。
        
        分代垃圾回收
        分代垃圾回收算法是一种优化的垃圾回收算法，它将对象分为不同的代，并使用不同的垃圾回收策略。Python的分代垃圾回收机制会将所有对象分为三代，分别是0代、1代和2代，每代对象的回收策略也不同。其中，0代对象的回收策略是基于频度，1代对象的回收策略是基于时间，而2代对象的回收策略则是基于空间。当对象在分代垃圾回收过程中经过多次回收仍未被回收时，会被转移至更高一代的对象中进行进一步回收。

调优手段：
    
    尽量缩小变量作用域，及时删除不需要的对象。
    
    使用生成器而不是列表来存储大量数据。
    
    使用标准库中的内置函数，如map、filter、reduce等，减少循环次数和内存占用。
    
    使用numpy代替纯Python代码处理大量数据。
    
    使用Cython或其他编写Python扩展的工具，将性能敏感的代码实现为C语言扩展。
    
    使用内存映像文件而不是将数据加载到内存中。
                
        以下是一个简单的例子，演示如何使用Python标准库中的mmap模块来实现内存映像文件：
        
        import mmap
        
        # 打开文件并将它映射到内存中
        with open("data.txt", "r+b") as f:
            # 读取文件的大小并将其映射到内存中
            file_size = os.stat("data.txt").st_size
            mmapped_file = mmap.mmap(f.fileno(), file_size)
        
            # 从内存映像文件中读取数据，这里假设文件中存储的是一些字符串
            print(mmapped_file.readline())
            print(mmapped_file.readline())
            print(mmapped_file.readline())
        
            # 在内存映像文件中查找某个字符串并替换它
            mmapped_file.seek(0)
            search_str = b"hello"
            replace_str = b"hi"
            replace_count = 0
            while True:
                found_pos = mmapped_file.find(search_str)
                if found_pos == -1:
                    break
                mmapped_file[found_pos:found_pos+len(search_str)] = replace_str
                replace_count += 1
        
            # 将修改的内容同步写回到磁盘上
            mmapped_file.flush()
        
            # 解除映射关系
            mmapped_file.close()

        在这个例子中，我们首先打开一个名为data.txt的文件，并将它映射到内存中。然后我们从内存映像文件中读取了一些数据，并在内存映像文件中查找并替换了某个字符串。最后，我们将修改后的内容同步写回到磁盘上，并解除内存映射关系。这种方式可以大大减少文件读写所需的时间和资源，提高程序的效率。
    
    对于长生命周期的对象，尽量使用较小的数据类型，如使用int代替float等。
    
    使用局部变量代替全局变量，减少内存占用。
    
    使用第三方工具和库，例如memory_profiler、objgraph和pympler，帮助识别和解决内存泄漏和性能瓶颈问题。



#### Mysql怎么限制IP访问

可以通过`MySQL`的`访问控制列表（ACL Access Control List）`来`限制IP访问`。

`ACL`包括`允许访问的用户`和`服务器IP地址范围`。
在MySQL中，有两个`系统表`存储着这些信息，分别是`mysql.user`和`mysql.db`。`


如果要限制`某个用户`在`特定IP地址下`的访问权限，可以使用以下命令：

    GRANT ALL PRIVILEGES ON database_name.* TO 'username'@'ip_address' IDENTIFIED BY 'password';

        database_name是数据库名
        username是用户名
        ip_address是允许访问的IP地址，password是密码。

        这样就限制了该用户只能从指定的IP地址访问该数据库。

如果要限制`所有用户`在`特定IP地址下`的访问权限，可以在`mysql.user`表中添加一条记录（如果没有的话）：

    INSERT INTO mysql.user (Host, User, Password) VALUES ('ip_address', '%', PASSWORD('password'));

        ip_address是允许访问的IP地址，’%’表示所有用户，password是密码。

        这样就限制了所有用户只能从指定的IP地址访问MySQL服务器。

添加完记录后，需要使用以下命令使其生效：

    FLUSH PRIVILEGES;

这样就可以限制IP访问了。

当然，在生产环境下，我们通常还需要使用防火墙等其他方法加强安全性。


#### 设计模式 

设计模式是一种解决软件设计问题的通用方法，它可以在特定情况下提供优雅、高效、可维护的解决方案。

设计模式是由经验丰富的开发人员创建的，它们已经反复证明，在不同的应用环境中都是可行的。

以下是几个比较常见的设计模式：

    工厂模式（Factory Pattern）
        工厂模式是一种创建型设计模式，它允许开发人员通过抽象工厂类来创建一组相关或相互依赖的对象，而不必指定它们的具体类。这样的方式可以使代码更加灵活和可扩展。
    
    单例模式（Singleton Pattern）
        单例模式是一种创建型设计模式，它保证一个类只有一个实例，并提供全局访问点来访问该实例。它通常用于管理共享资源，如一个数据库连接池。
    
    观察者模式（Observer Pattern）
        观察者模式是一种行为型模式，它定义了对象之间的一对多依赖关系，使得当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知并自动更新。
    
    策略模式（Strategy Pattern）
        策略模式是一种行为型模式，它定义了一系列算法，将每个算法都封装起来，并使它们之间可以互换。该模式使算法的变化独立于使用它们的客户端。
    
    装饰器模式（Decorator Pattern）
        装饰器模式是一种结构型模式，它允许开发人员在运行时给一个对象动态地添加额外的职责，而不会影响到其他对象。
        这种方式可以避免使用子类创建复杂的对象，同时也在一定程度上实现了开闭原则。

以上是我了解的几个设计模式，它们都可以帮助开发人员设计出优秀的软件，在实际项目中有广泛应用。



#### python 面向对象有三大特性：`封装、继承、多态`


`封装`

    封装可以通过将数据和方法封装在一个类中，防止外部代码直接访问对象的内部数据和方法。


可以通过类的访问控制实现封装，例如：

```python
# 定义一个Person类，将数据和方法封装在类中
class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

    def say_hello(self):
        print("Hi, my name is", self.name, "and I am", self.age, "years old.")

# 创建一个Person对象并调用对象的公开方法
p = Person("John", 30)
p.say_hello()

# 尝试直接访问对象的数据，将会引发AttributeError异常
print(p.name)

# 在这个示例中，Person类将数据和方法封装起来，外部代码无法直接访问对象的内部数据self.name。
# 而使用公开的方法say_hello()来间接访问数据。

```

`继承`

    继承允许一个类继承另一个类的属性和方法，并可以在子类中添加、重写或者替换父类的属性和方法。例如：

```python
# 定义一个Animal类，它有一个公共方法make_sound()
class Animal:
    def make_sound(self):
        pass

# 定义一个Dog类，它继承自Animal类，并重写父类的方法make_sound()
class Dog(Animal):
    def make_sound(self):
        print("Woof")

# 定义一个Cat类，它继承自Animal类，并替换父类的属性和方法
class Cat(Animal):
    def __init__(self, name):
        self.name = name

    def make_sound(self):
        print("Meow")

# 创建一只狗和一只猫，并调用它们的公共方法make_sound()
d = Dog()
c = Cat("Tom")

d.make_sound()
c.make_sound()
# 在这个示例中，Dog和Cat类都继承自Animal类，它们分别重写或替换了父类的方法，实现了自己的make_sound()方法。

```

`多态`

    多态指的是同一种对象在不同的情况下表现出不同的行为。在Python中，多态可以通过重载运算符、接口和类方法等方式实现。例如：

```python
# 定义一个Animal类，它有一个公共方法make_sound()
class Animal:
    def make_sound(self):
        pass

# 定义一个Dog和Cat类，它们都重载了父类的make_sound()方法
class Dog(Animal):
    def make_sound(self):
        print("Woof")

class Cat(Animal):
    def make_sound(self):
        print("Meow")

# 定义一个函数，它接受一个Animal对象并调用make_sound()方法
def make_some_noise(animal):
    animal.make_sound()

# 创建一只狗和一只猫，并将它们传递给函数make_some_noise()
d = Dog()
c = Cat()

make_some_noise(d)
make_some_noise(c)

# 在这个示例中，make_some_noise()函数接受一个Animal对象，并调用它的make_sound()方法。
# 在函数的实际调用中，我们传递了一个狗对象和一只猫对象，它们都重载了make_sound()方法，并实现了不同的行为。
# 这就体现了Python的多态特性。
```


#### Python提供包括`管道、队列、共享内存` 进程间通信的方式

`管道（Pipe）：`

管道是一种基于`文件句柄`的进程间通信方式，在父进程和子进程之间创建一个输入输出的管道，可以通过这个管道进行双向通信。

```python
import multiprocessing

def worker(conn):
    conn.send([42, None, 'hello'])
    conn.close()

if __name__ == '__main__':
    # 创建管道
    parent_conn, child_conn = multiprocessing.Pipe()
    # 创建子进程并启动
    p = multiprocessing.Process(target=worker, args=(child_conn,))
    p.start()
    # 父进程从管道中接收数据
    print(parent_conn.recv()) # prints "[42, None, 'hello']"
    p.join()
    
# 在上述代码中，我们通过multiprocessing.Pipe()方法创建了一个双向管道，这个管道将由父子进程共享。
# 在子进程中，我们向管道中写入了一个列表，之后关闭管道。
# 在父进程中，我们通过recv()方法从管道中接收数据。

```

`队列（Queue）：`

队列是Python中线程和进程安全的通信方式，它提供了多种队列类型，包括FIFO队列、优先级队列等。
在多个进程间共享的队列中，进入数据会被多个进程消费，多个进程添加数据都不会冲突。

```python
import multiprocessing

def worker(q):
    for i in range(10):
        q.put(i)
    q.put(None)

if __name__ == '__main__':
    # 创建队列
    q = multiprocessing.Queue()
    # 创建子进程并启动
    p = multiprocessing.Process(target=worker, args=(q,))
    p.start()
    # 父进程从队列中取数据
    while True:
        data = q.get()
        if data is None:
            break
        print(data)
    p.join()
    
# 在上述代码中，我们通过multiprocessing.Queue()方法创建了一个队列，这个队列将由父子进程共享。
# 在子进程中，我们将一定数量的数据放入队列中，并在最后放入None对象用于表示队列的结束。
# 在父进程中，我们会从队列中持续取出数据，并进行处理，当取出数据为None时，结束循环。

```

`共享内存（Value和Array）：`

共享内存是一种不同于其他通信方式的高效方式，可以在多个进程中共享内存，不需要在进程间传递大量数据。
Python中提供了Value和Array等两个用于共享内存的数据结构。

```python
import multiprocessing

def worker(num, arr):
    num.value += 1
    for i in range(len(arr)):
        arr[i] = arr[i] * 2


if __name__ == '__main__':
    # 创建共享内存数据
    num = multiprocessing.Value('i', 0)
    arr = multiprocessing.Array('i', range(10))
    # 创建子进程并启动
    p = multiprocessing.Process(target=worker, args=(num, arr))
    p.start()
    # 等待子进程结束
    p.join()
    # 打印共享内存数据
    print(num.value)
    print(arr[:])
    
# 在上述代码中，我们通过multiprocessing.Value()方法创建了一个内存中的值和一个multiprocessing.Array()方法创建了一个数组，
# 这两个数据结构将由父子进程共享。在子进程中，我们修改了num的值并对数组元素进行了一定的运算。
# 在父进程中，我们等待子进程结束并打印出共享内存数据。
```

#### 什么是`僵尸进程`和`孤儿进程`？怎么避免僵尸进程？

`僵尸进程`是指子进程结束后，其在内核中的进程描述符依然存在，但其父进程没有及时处理孩子退出的消息。

`孤儿进程`是指父进程异常退出，而子进程没有及时退出或被其他进程所接管的进程。

避免僵尸进程的方法：

    父进程使用wait或waitpid函数等待子进程结束，及时回收子进程资源。
    
    在创建子进程后，通过设置信号的处理函数来回收子进程资源。当子进程结束时，会向其父进程发送SIGCHLD信号，父进程可以通过信号处理函数处理该信号，并调用wait或waitpid函数等待子进程结束，及时回收子进程资源。
    
    使用守护进程的方式避免僵尸进程的产生。守护进程是一种长期运行的后台进程，可以通过调用setsid函数、关闭文件描述符等操作创建，它不依赖于终端，不与任何控制终端产生关联，也不会受到用户登录或退出的影响。
    
    需要注意的是，在使用wait或waitpid等函数等待子进程结束时，要防止使用错误的选项或参数，导致进程阻塞或无法回收子进程资源。



#### 简述浏览器通过`WSGI`请求动态资源的过程

浏览器通过WSGI请求动态资源的过程：

    用户在浏览器中输入网址，浏览器向服务器发送HTTP请求。
    
    服务器接收到请求后，调用相应的WSGI应用程序处理请求。
    
    WSGI应用程序根据请求的路径、请求方法等信息，调用相应的Python函数处理请求。
    
    Python函数根据请求的逻辑，生成响应数据。
    
    响应数据返回给WSGI应用程序，通过WSGI服务器返回给浏览器。
    
    浏览器接收响应数据，进行渲染展示。

需要注意的是

`WSGI应用程序`通常由Web框架负责实现，如`Django、Flask`等；

`WSGI服务器`实现有很多，如`Gunicorn、uWSGI、mod_wsgi`等，可以根据实际需要选择合适的服务器。



#### 用浏览器访问`www.baidu.com`的过程如下：

    
    用户在浏览器地址栏中输入www.baidu.com并按下回车键。
    
    浏览器向DNS服务器发送一个请求，询问www.baidu.com的IP地址。
    
    DNS服务器返回www.baidu.com的IP地址（通常是多个）
    
    浏览器通过IP地址连接到百度的服务器，并发送HTTP请求。
    
    百度服务器接收到HTTP请求后，根据请求的URL路径和参数，响应相应的HTML文档。
    
    浏览器接收到HTML文档后，开始渲染文档，并向服务器请求HTML文档中的其他资源，如图片等。
    
    服务器提供所需的其他资源，并响应浏览器的请求，浏览器渲染并显示整个页面。

需要注意的是，此过程可能涉及到缓存、HTTPS协议等细节问题。



#### HTTP中最常用的请求方式有两种：GET和POST 

`GET`和`POST`是HTTP协议中最常用的两个请求方式，它们在`发送数据`和`接收数据`的方式上有不同。


`GET请求`：获取数据，常用于读取数据和信息展示的场景。

`POST请求`：提交数据，常用于提交表单、上传文件等场景。


Post和Get请求的区别:

`参数位置不同`

    GET请求方法是将请求信息包含在URL中，而不是在包含请求数据的HTTP消息主体中。例如：http://www.example.com/path/file.html?arg1=123&arg2=abc

    POST请求方法是将请求数据在请求消息主体中发送。而不是在URL中。例如：http://www.example.com/path/file.html

`对数据大小的限制不同`

    GET请求访问的数据大小有限制，一般在2KB之内，因为数据需要在URL中传递。

    POST请求则没有大小限制，因为数据在消息主体中传递。

`请求安全性不同`

    GET请求的数据是以明文形式出现在URL中，所以不安全，可能会暴露数据。

    POST请求将数据封装在请求消息主体中，不会暴露在URL中，相对比较安全。


`缓存机制不同`

    GET请求可以被浏览器缓存

    POST请求不能被浏览器缓存。



总之，GET请求一般用于传输少量数据，不包含敏感信息；而POST请求用于传输数据量较大，包含敏感信息的情况。


#### cookie 和session 和jwt的区别， 以及应用场景


`Cookie`、`Session`和`JWT`都是用于`用户身份验证的技术`，它们有着不同的工作原理和应用场景。


`Cookie`

`Cookie`是服务器发送到浏览器并`保存在本地`的一小段数据，以便在用户访问网站时存储和检索相关信息。它可以在不同的页面中传递信息，也可以在用户关闭浏览器后依然存在。

Cookie通常用于  `维护用户的登录状态` 和 `跟踪用户的行为`, 可以通过设置Cookie的属性来实现过期时间、安全性、域和路径等。

    应用场景：

        `Cookie`最常见的应用场景是用于`用户认证`和`用户行为跟踪`，例如`网站的登录状态`、`购物车中的商品`、`用户主题首选项`等。


`Session`

`Session`是在服务器端存储的一段数据，用于跟踪用户的会话状态。需要借助 `cookie` 实现

每个`Session`都有一个唯一的`Session ID`，该ID在每个用户与应用程序交互时都会传递，以便在服务器端进行数据的读取和修改。

`Session`可以在应用程序中存储各种类型的数据，如用户信息、购物车中的商品、访问权限等。

    应用场景：
        `Session`通常用于`用户认证`和 `管理状态信息`，例如在 服务器端记录`用户登录状态`，`检查权限`和`访问控制模型`等。

`JWT`

`JWT（JSON Web Token）`是一种安全的身份验证方式，通过在网络应用之间传递信息来验证用户的身份。

它使用JSON格式来封装信息，并使用加密算法将信息签名，以确保信息的完整性和安全性。

`JWT`通常包含用户信息、有效期和签名等。`JWT`可以很容易地在不同的应用程序之间共享，因为它是`轻量级`的，不需要在服务器端进行存储和验证。

    应用场景：

        `JWT`最常见的应用场景是在 `分布式系统中`进行身份验证和授权，如`单点登录系统`、`API鉴权`等。


总之，Cookie、Session和JWT都是用于用户认证和维护状态的技术，根据不同的应用场景和安全要求选择不同的技术实现可以提高系统的可靠性和安全性。


#### HTTP协议的状态码

`HTTP协议的状态码`分为五类，分别是`1xx、2xx、3xx、4xx和5xx`，下面是状态码的具体含义：


`1xx（提供信息）`

    100：继续请求，客户端应该继续发出请求。
    
    101：协议切换，服务器正在切换到一个不同的协议（例如HTTP/2）。


`2xx（成功）`

    200：请求成功，服务器已经成功处理了请求。
    
    201：创建成功，请求已经成功创建一个新的资源。
    
    204：无内容，服务器成功处理了请求，但返回的响应报文不包含实体的主体部分。
    
    206：部分内容，服务器成功处理了范围请求。

`3xx（重定向）`

    301：永久重定向，在请求的资源被永久性转移时使用。
    
    302：临时重定向，在请求的资源临时性转移时使用。
    
    304：未修改，客户端发送了一个带条件的GET请求，服务器告诉客户端资源未被修改，可以使用缓存的响应。
    
    307：临时重定向，与302状态码含义相似，但不允许将POST变成GET。

`4xx（客户端错误）`

    400：请求无效，由于客户端发送的请求有误而无法被服务器处理。
    
    401：未授权，需要客户端先进行身份验证后，才能访问请求的资源。
    
    403：禁止访问，客户端没有访问资源的权限。
    
    404：未找到，客户端请求的资源不存在。
    
    405：方法不被允许，服务器禁止使用该方法访问资源。

    `4xx`表示客户端请求有误或者请求无法被服务器响应。


`5xx（服务器错误）`

    
    500：服务器错误，服务器遇到了一个未知的错误，无法完成该请求。
    
    502：错误网关，服务器作为网关或代理时，从上游服务器接收到无效的响应。
    
    503：服务不可用，服务器当前无法处理请求，一段时间后可能会恢复正常。

    `5xx`表示服务器遇到错误或无法处理请求。



#### 什么是`tcp`的`2MSL`

`2MSL`是`TCP协议中的一个计时器`，全称为`”2 Maximum Segment Lifetime”`，中文翻译为`“两倍的最大报文段寿命”`。

它是`为了确保TCP连接被彻底释放`而设立的一个定时器。

    2MSL发生在TCP连接的最后一步，即在四次挥手的最后一个阶段

    即客户端发送最后一个ACK报文段后，会进入TIME-WAIT状态，并等待2MSL时间，以确保双方都没有数据包需要发送，从而安全地关闭连接。
    在2MSL时间结束后，客户端才会彻底关闭连接，释放相关资源。
    因此，2MSL时间是四次挥手的最后一个阶段，也是TCP连接关闭的最后一步。

`2MSL`的时间通常为2倍的`MSL`，也就是`两个通信节点之间最长的存活时间`，一般设置为`30秒`，MSL的值根据不同的操作系统和TCP协议的版本而定。

    经过2MSL的时间，说明可能滞留在网络中的连接请求已经彻底消失，从而保证没有任何数据报文段存在于网络中。

![](https://raw.githubusercontent.com/landybird/landybird.github.io/master/assets/images/tcp34.png)


- `客户端`在`TIME-WAIT状态`必须等待`2MSL`的时间主要出于以下几个原因：


    1  TCP连接的两个端点都可能在 关闭连接之前 发送其余的数据包，2MSL的时间长度保证了这些数据包在网络中完全消失，
       以充分清除整个连接，确保不会影响到其他连接。

    2  确保服务端可以收到客户端最后一个ACK报文段，因为服务端在发送FIN报文段后，一定要收到客户端对该报文段的确认包ACK，
       才能够准确地确认TCP连接已经关闭，释放相关资源。

    3  防止已失效的连接请求重新出现并导致错误，在时间等待期间，发送重复的FIN报文段也无法导致重新打开连接。

    因此，2MSL时间的作用是确保TCP连接被完全关闭，从而保证网络上的稳定性，防止新旧连接之间产生冲突，确保数据传输的正确性和可靠性。




#### HTTP和HTTPS区别

`HTTP (HyperText Transfer Protocol)`是一种基于`TCP/IP协议`的传输协议，

用于传输Web上的数据，常用于从Web服务器传输超文本到本地浏览器。

HTTP是明文传输，安全性不高。


`HTTPS (HTTP Secure)`是基于HTTP的安全协议，通过使用`SSL/TLS`协议来加密HTTP的内容。

使用HTTPS可以提供加密、身份验证和完整性保护等安全特性，保护用户隐私和Web应用安全。

这是通过在传输层(TCP)和网络层(IP)之间添加`TLS/SSL`层实现的。


因此，HTTP与HTTPS的主要区别在于：

    HTTPS是加密传输协议，HTTP是明文传输协议。
    
    HTTPS会通过TLS/SSL协议验证服务器的身份，从而提高通信的安全性。

    HTTPS可以防止中间人攻击和窃听、修改等安全隐患，从而保护用户的私密信息。

总之，HTTP与HTTPS之间的主要区别就是安全性。HTTPS用于加密Web通信而HTTP不是。
HTTPS更适用于传输帐号和密码、信用卡信息等敏感数据。


#### HTTP 通过以下几种方法来`保证安全传输`：

    HTTPS 协议：

        HTTPS 是 HTTP 的安全版本，可以通过使用 SSL 或 TLS 加密技术来确保网络通讯的安全性。
        例如，https://www.google.com 这个 URL 就使用了 HTTPS 协议来加密网络通讯，提供更加安全的搜索服务。
    
    SSL/TLS 加密技术：

        通过 SSL 或 TLS 加密技术，可以对 HTTP 的数据进行加密和解密，以保障网络通讯的安全。
        例如，当用户在网上购物时，其输入的支付信息将通过 SSL/TLS 加密技术进行保护，以避免支付信息被黑客窃取或篡改。
    
    密码学技术：

        HTTP 可以使用密码学技术对数据进行加密和解密，以确保数据传输的安全性。
        例如，当用户在进行在线银行转账时，其输入的密码将通过密码学技术进行加密，使其难以被黑客破解。
    
    数字证书及数字签名：
        
        HTTP 可以使用数字证书和数字签名来验证数据的真实性和完整性。
        例如，访问一个网站时，浏览器会检查该网站的数字证书，以确保该网站是真实的，并且数据在传输过程中没有被篡改。

通过以上方法，HTTP 可以保证信息传输的安全性和可靠性，使用户可以安心地进行网络通讯和在线交易。


#### SSL、TLS、mTLS 通信安全协议


`SSL（Secure Sockets Layer）`和`TLS（Transport Layer Security）`是常用的`通信安全协议`，用于网络通信的加密、认证和数据完整性保护。


`SSL` 是一种早期的协议，后来被 `TLS `所取代，TLS 的版本从 1.0 至 1.3 不断更新完善。

    传统的 SSL/TLS 是单向认证，只需要服务端提供证书，客户端验证服务器证书的有效性即可。


    SSL/TLS 使用公钥和私钥进行加密通信，其中，公钥用于加密发送方的数据，而私钥用于解密接收方的数据。
    协议还包括数字证书和证书信任链，用于验证通信双方的身份和建立可信连接。


    SSL/TLS 通信协议广泛应用于 Web 等 Internet 应用中，可以使用 HTTP 协议（HTTPS）或其他应用层协议进行通信。


`mTLS（Mutual TLS）`是一种基于证书的双向认证机制，也称为`双向 SSL`。

    mTLS 在服务端和客户端之间建立双向信任关系，客户端需要提供自己的证书，服务端验证客户端证书的有效性。
    这种机制可以提高通讯的安全性，进一步防止中间人攻击和伪装攻击等。


    mTLS 将双向认证机制应用于 SSL/TLS 通信中，客户端与服务端之间需要提供证书进行身份认证。

    mTLS 广泛应用于微服务、容器化应用、API 网关等场景，可以提高应用之间的安全通信能力。


#### HTTP协议头部中`表示数据类型`的字段是`Content-Type`

HTTP协议是`HyperText Transfer Protocol`的简写，是一种用于Web应用程序和Web服务器之间交互数据的协议。

HTTP使用一个客户端-服务端模型，通过在客户端发起请求并由服务器进行响应的方式，来实现数据传输和通信。

HTTP协议头部中表示数据类型的字段是`Content-Type`。它指定了HTTP消息体中的媒体类型。

常见的媒体类型有`text/html、text/plain、application/json、image/jpeg`等。

Content-Type的常见取值如下：
    
    text/html——HTML格式
    
    text/plain——纯文本格式
    
    application/json——JSON数据格式
    
    application/xml——XML数据格式

Content-Type的格式如下：

    Content-Type: type/subtype; parameter=value

其中，type表示大类别，subtype表示小类别，parameter表示参数，value为参数值，多个参数以分号隔开。

    例如，Content-Type: text/html; charset=UTF-8，表示该文本是采用UTF-8编码的HTML格式。

在响应头中，Content-Type是必须要包含的字段，而在请求头中，则可选传输。


#### HTTP请求方法


`HTTP请求方法`是指 客户端对于服务器的行为请求方式，HTTP定义了多种请求方法，常用的有以下几种：

    GET：用于获取指定资源的信息。请求参数通过URL传递，不安全。
    
    POST：用于向指定资源提交数据，请求参数在请求体中传递，适合传递大量数据。
    
    PUT：用于将请求的数据存储到指定位置，不区分新建或者修改。安全性较低。
    
    DELETE：用于请求服务器删除指定的资源，但是不保证被删除。
    
    HEAD：和GET类似，但是服务器只返回请求头信息，不返回实际数据。
         可以用于检测资源是否可用，判断文件是否修改等。

    OPTIONS：用于获取资源的通信选项，常被用于 预检请求 等。
    
    CONNECT：用于开启服务器与客户端之间的隧道（通常用于SSL加密的TCP通信）。

    TRACE：执行一个假的请求来追踪请求-响应链。

如果需要定义新的方法，需要遵循HTTP协议的规范并在请求头中定义该方法。

不同的请求方法有不同的特点和应用场景，开发者需要根据具体需求选择。


#### 用`Socket套接字`需要传入以下参数：

    
    Address family（地址族）：指定网络通信的协议族，常见的有IPv4和IPv6。
    
    Socket type（套接字类型）：指定通信协议的类型，常见的有 面向连接的流式套接字 和 面向消息的数据报式套接字。

    Protocol（协议）：指定网络协议类型，如TCP、UDP、RAW等。

这些参数通常在创建Socket时传入，例如在Python中创建TCP套接字可以用如下代码：
```python
import socket
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
```

    这里传入了
    Address family 为IPv4，
    Socket type 为面向连接的流式套接字
    Protocol 为TCP。

    其中socket.AF_INET和socket.SOCK_STREAM都是Python内置的常量，分别对应IPv4的地址族和面向连接的流式套接字。


#### HTTP 常见请求头

    
    
    Accept：指定客户端能够接收的内容类型。

    Accept-Charset：指定客户端能够接收的字符集。

    Accept-Encoding：指定客户端能够接收的内容压缩格式。

    Accept-Language：指定客户端能够接收的自然语言。

    Authorization：指定客户端的身份认证信息。

    Cache-Control：指定请求和响应的缓存机制。

    Connection：指定客户端和服务器之间连接的状态。

    Content-Length：指定请求或响应的内容长度。

    Content-Type：指定请求或响应的内容类型。

    Cookie：指定客户端要发送的Cookie。

    Host：指定请求的目标主机。

    If-Modified-Since：指定客户端发送请求的内容的修改时间，用于缓存控制。

    If-None-Match：指定客户端要检查的实体标签，用于缓存控制。

    Pragma：指定客户端和服务器的缓存机制。

    Referer：指定请求来源的URL。

    User-Agent：指定客户端的浏览器类型和操作系统信息



#### `URL（Uniform Resource Locator）`的形式通常为：


    [协议]://[域名或IP地址][:端口号]/[路径]?[查询参数]#[锚点]

例如：

    https://www.example.com:8080/index.html?param1=value1&param2=value2#section1

    协议：例如HTTP、HTTPS、FTP。

    域名或IP地址：指定服务器的地址。

    端口号：HTTP协议默认端口号为80，HTTPS协议默认端口号为443，如果需要访问其他端口，则需要在URL中指定。
    
    路径：指定服务器上的文件路径。

    查询参数：用于向服务器传递额外的数据或指令。

    锚点（或称片段）：用于指定网页中的特定位置，浏览器会自动跳转至该位置。



#### 对Flask蓝图(Blueprint)的理解


`Flask`蓝图(Blueprint)是一种`将应用程序拆分为可复用组件`的机制。它是在Flask应用程序中组织视图和其他代码的最佳实践方法之一。

在Flask中，蓝图是一种独立于应用程序的可重复使用组件，可以用于组织一个应用程序的视图、模板、静态文件和其他代码。
蓝图和应用程序一样，可以有自己的路由和视图函数，并且还可以有自己的模板目录和静态文件目录。在蓝图中定义的路由和视图函数可以包含相对路径，并且可以与应用程序的路由和视图函数组合在一起工作。

    使用蓝图可以将应用程序划分为多个独立的模块，使代码更加清晰易懂，并可以简化应用程序的测试和维护工作。
    蓝图还可以在单个应用程序中组织不同的API，方便不同的开发人员使用不同的API。

总的来说，蓝图是Flask中将应用程序分解为可重用组件的最佳实践方法之一，可以大大提高应用程序的可维护性和可伸缩性。


```python
# 1.创建一个蓝图对象

blue = Blueprint("blue",__name__)

# 2.在这个蓝图对象上进行操作，例如注册路由、指定静态文件夹、注册模板过滤器...

@blue.route('/')
def blue_index():
    return "Welcome to my blueprint"

# 3.在应用对象上注册这个蓝图对象

app.register_blueprint(blue,url_prefix="/blue")
```


#### `Flask` 和 `Django` 路由映射的区别


Flask和Django都是Web框架，但它们的`路由映射机制`略有不同。

在`Flask`中，路由映射是通过装饰器来实现的。

    通常会使用视图函数对不同的URL进行处理，并将函数使用@app.route()装饰器绑定到对应的URL上。例如：

```python
from flask import Flask

app = Flask(__name__)

@app.route("/")
def index():
    return "Hello World!"

# 这个代码片段定义了一个名为index的视图函数，它将响应在根URL（”/“）上的请求。

# 在Flask中，路由映射可以使用其他的HTTP方法绑定到相同的URL上。例如：

@app.route("/user/<username>")
def show_user_profile(username):
    return "User {}".format(username)

@app.route("/user/<username>/edit")
def edit_user_profile(username):
    return "Editing User {}".format(username)

# 这个代码片段展示了在Flask中如何绑定带变量的URL（即动态路由）。

# 在这个例子中，路由映射了/user/john和/user/peter这样的URL，并从其中的变量进行提取。

```

在`Django`中，路由映射是通过`URLconf（URL配置）文件或包中的模块`来实现的。

每个模块定义一个或多个视图函数，并在`URLconf`中将这些`视图函数`绑定到`对应的URL`。例如：

```python
from django.urls import path
from . import views

urlpatterns = [
    path('', views.index, name='index'),
    path('user/<username>/', views.show_user_profile, name='show_user_profile'),
    path('user/<username>/edit', views.edit_user_profile, name='edit_user_profile'),
]

# 在这个例子中，URLconf文件定义了三个路由，分别对应根URL（”/“）和两个带变量的URL（即动态路由）。


```

总的来说，Flask和Django都提供了路由映射来实现请求和视图函数之间的关系，

    Flask使用 装饰器 将视图函数与路由关联，
    
    Django使用 URLconf 将视图函数与路由关联。


无论使用哪种方式，都可以实现适当的路由映射，并为Web应用程序提供有用的API。


#### wsgi, uwsgi, uWSGI 的关系


1 `WSGI`是`Web Server Gateway Interface`的缩写，定义了一种规范，为`Python Web应用程序和Web服务器之间的协作提供了一个标准化接口`。
它允许`Web应用程序`和`Web服务器`进行通信，尤其是通过调用应用程序代码中的可调用对象（通常是函数或方法）来处理请求和生成响应。

    WSGI本身只是一种协议规范，并不提供Web服务器或应用程序服务器的实现。

2 `uWSGI`是一种`Web服务器`，既可用作Web应用程序服务器，也可以与其他Web服务器（如NGINX或Apache）进行协作。
它实现了`WSGI协议`，与Python的WSGI应用程序接口很好地集成，并可以通过多个协议（如HTTP、FastCGI等）进行通信。
uWSGI还支持异步、多线程、多进程和协程模型等特性，用于提高Web应用程序的性能以及灵活性。


3 `uwsgi`是一种使用uWSGI实现WSGI协议的特定格式的协议，它是uWSGI服务器的独占协议

因此，可以这样总结它们之间的关系：

    WSGI是定义了Python Web应用程序和Web服务器之间通信的协议规范；
    uWSGI是一种实现了WSGI协议的Web服务器和应用程序服务器；
    uwsgi则是与uWSGI服务器通信的一个特定格式的协议。


#### Django、Flask、Tornado, fastapi 的对比


    Django：Django是一种完全的Web应用程序框架，它提供了许多默认配置和工具，可以快速开发复杂的Web应用程序。
            Django具有强大的ORM功能，拥有大量的插件和社区支持。
            但是，Django的复杂性和约束性较高，需要遵守其固定的开发方式。

    Flask：Flask是一种轻量级的Web框架，它提供了最基本的Web开发工具，通过良好的扩展性，可以根据需要添加更多的功能。
            Flask最大的优势在于其简单而灵活的结构，可以根据自己的需要自由发挥。
            但是，相对而言，Flask的性能和规模较小。

    Tornado：Tornado是一种异步Web框架，它的主要特点是处理Web请求数量大时的稳定性和可伸缩性。
            Tornado适用于管理大量WebSockets连接和处理高并发请求的场景。
            但是，Tornado的使用门槛较高，需要去理解异步编程方式，而且其面向的应用场景也较为特殊。

    FastAPI：FastAPI是一种基于Python3.6+的Web框架，它使用了Python的Type Hints和AsyncIO实现快速API开发，具有强大的性能和可扩展性。
            FastAPI的开发方式类似于Flask，但是其基于ABNF（Abstract Syntax Notation One Form）模型实现，可以自动生成OpenAPI文档，大大提高了开发效率。

综上，这些框架各具特色，根据具体的应用需求，选择适合的框架应该是基于开发权衡的一个评估过程。


#### Django请求生命周期的大致过程如下：
    
    1 客户端向Django的Web服务器发起请求。
    
    2 Web服务器将请求传递给Django框架，Django框架根据路由规则查找到对应的视图函数。

    3 Django框架将请求封装成HttpRequest对象，发送给对应的视图函数进行处理。

    4 视图函数对HttpRequest对象进行处理，生成HttpResponse对象，将响应发送回Web服务器。

    5 Web服务器将HttpResponse对象发送回客户端，并结束本次请求响应过程。

在这个过程中，Django框架实现了许多功能，如URL路由、请求上下文、请求中间件、模板引擎等，为开发人员提供了强大的功能和便捷的开发方式。


#### Python中三大框架各自的应用场景 

django:主要是用来搞快速开发的，他的亮点就是快速开发，节约成本，如果要实现高并发的话，就要对django进行二次开发 

    比如把整个笨重的框架给拆掉自己写socket实现http的通信,底层用纯c,c++写提升效率，ORM框架给干掉，自己编写封装与数据库交互的框架
    ORM虽然面向对象来操作数据库，但是它的效率很低，使用外键来联系表与表之间的查询; 

flask: 轻量级，主要是用来写接口的一个框架，实现前后端分离，提考开发效率，Flask本身相当于一个内核，其他几乎所有的功能都要用到扩展

    (邮件扩展Flask-Mail，用户认证Flask-Login),都需要用第三方的扩展来实现。比如可以用Flask-extension加入ORM、文件上传、身份验证等。
    Flask没有默认使用的数据库，你可以选择MySQL，也可以用NoSQL。

    其WSGI工具箱用Werkzeug(路由模块)，模板引擎则使用Jinja2,这两个也是Flask框架的核心。

Tornado： Tornado是一种Web服务器软件的开源版本。

Tornado和现在的主流Web服务器框架（包括大多数Python的框架）有着明显的区别：

    它是非阻塞式服务器，而且速度相当快。
    得利于其非阻塞的方式和对epoll的运用，Tornado每秒可以处理数以千计的连接因此Tornado是实时Web服务的一个理想框架



#### 找出 1G 的文件中高频词


对于较大的文件，可以考虑将其`分块读取`和`分布式计算`，以提高处理效率。以下是一些实现方式的简述：

- `分块读取`

> 方式一：按行读取

在上述示例代码中，我们逐行读取了整个文件，对于较小的文件这种方式可以处理，但对于大型文件来说，逐行读取相当于每次只处理一个文本行，处理效率较低。
一种更好的方式是将文件分成固定大小的块，逐块读取并处理。

示例代码：

```python
import re
from collections import Counter

def get_high_freq_words(file_path, block_size=100000000, top_k=10):
    # 定义正则表达式，用于分割单词
    regex = re.compile(r'\b[a-zA-Z]+\b')

    # 定义计数器，用于统计每个单词的出现次数
    word_counter = Counter()

    # 以块为单位读取文件，并统计每个单词的出现次数
    with open(file_path, 'r', encoding='utf-8') as f:
        while True:
            block = f.read(block_size)
            if not block:
                break
            words = regex.findall(block)
            word_counter.update(words)

    # 获取出现频率最高的前 top-k 个单词
    high_freq_words = word_counter.most_common(top_k)

    return high_freq_words

# 测试代码
file_path = 'path/to/your/file.txt'
high_freq_words = get_high_freq_words(file_path, block_size=100000000, top_k=10)
print(high_freq_words)
```

> 方式二：按大小分块

根据文件大小均分成若干块，然后逐块读取并处理。该方法可以避免读取过长的行导致内存溢出的问题。

示例代码：
```python
import re
from collections import Counter
import os

def get_file_size(file_path):
    return os.stat(file_path).st_size

def get_high_freq_words(file_path, block_num=10, top_k=10):
    # 计算每块大小
    file_size = get_file_size(file_path)
    block_size = file_size // block_num

    # 定义正则表达式，用于分割单词
    regex = re.compile(r'\b[a-zA-Z]+\b')

    # 定义计数器，用于统计每个单词的出现次数
    word_counter = Counter()

    # 按块读取文件，并统计每个单词的出现次数
    with open(file_path, 'r', encoding='utf-8') as f:
        for i in range(block_num):
            # 读取一块的内容
            block = f.read(block_size)

            # 处理最后一块时，可能文件不是整块大小，需要特殊处理
            if i == block_num - 1:
                block += f.read()

            words = regex.findall(block)
            word_counter.update(words)

    # 获取出现频率最高的前 top-k 个单词
    high_freq_words = word_counter.most_common(top_k)

    return high_freq_words

# 测试代码
file_path = 'path/to/your/file.txt'
high_freq_words = get_high_freq_words(file_path, block_num=10, top_k=10)
print(high_freq_words)
```

- 分布式计算

当处理大型文件时，可能需要借助分布式计算框架，将数据分布到多台机器上进行处理，可以显著提高处理速度。

以下是一些常用的分布式计算框架：
    
    Apache Hadoop
    Apache Spark
    Apache Flink
    Dask
    Ray

这些框架都提供了简单易用的API，可帮助用户实现分布式计算。虽然这些框架使用起来有些不同，但在处理大型文件时基本思路相同，即将文件分成多个块，将块分配给多台机器进行处理，最后将结果合并。
以下是一个用`Apache Spark`处理大型文件的示例代码：

```python
from pyspark import SparkConf, SparkContext
import re
from collections import Counter

def get_high_freq_words(file_path, top_k=10):
    # 定义Spark配置和上下文
    conf = SparkConf().setAppName("HighFreqWords")
    sc = SparkContext(conf=conf)

    # 定义正则表达式，用于分割单词
    regex = re.compile(r'\b[a-zA-Z]+\b')

    # 读取文件，并划分成多个块
    file_data = sc.textFile(file_path)
    blocks = file_data.repartition(10)

    # 逐块处理，统计每个单词的出现次数
    word_counter = blocks.flatMap(lambda line: regex.findall(line)) \
                      .map(lambda word: (word, 1)) \
                      .reduceByKey(lambda a, b: a + b) \
                      .map(lambda item: item[::-1]) \
                      .sortByKey(ascending=False) \
                      .take(top_k)

    # 停止Spark上下文
    sc.stop()

    return word_counter

# 测试代码
file_path = 'path/to/your/file.txt'
high_freq_words = get_high_freq_words(file_path, top_k=10)
print(high_freq_words)
# 该代码使用Apache Spark，将文件分成10个块，逐块处理并统计每个单词的出现次数，最后获取出现频率最高的前10个单词。需要注意的是，使用分布式计算框架时需要在多台机器上部署和运行，需要一定的分布式计算经验。
```

#### 怎么在海量数据中找出重复次数最多的一个

有多种算法可以在海量数据中找出重复次数最多的一个，以下是两种常用的方法：
    
    MapReduce

        MapReduce是一个分布式计算框架，可以用于处理大规模数据集。在MapReduce中，可以使用 Map 和 Reduce 两个操作来处理数据。具体地，在找出重复次数最多的一个时，可以进行以下步骤：
        
        Map 阶段：将海量数据分成多个块，并将每个块中的每个元素都映射成一个键值对。键表示元素的值，值为1。
        Shuffle 阶段：将 Map 阶段得到的键值对按键进行分组。
        Reduce 阶段：对每个键的值进行累加，得到每个元素的出现次数。
        最后，遍历 Reduce 阶段得到的键值对，可以找出重复次数最多的一个元素及其出现次数。
    
    布谷鸟哈希

        布谷鸟哈希是一种哈希表的实现方式，具有高效的查找和插入操作，并且可以动态调整哈希表的大小。具体地，在找出重复次数最多的一个时，可以进行以下步骤：
        
        将海量数据进行哈希，并将哈希值存储到布谷鸟哈希表中。
        对于哈希冲突的情况，可以使用链表等方法进行处理。
        遍历布谷鸟哈希表，找出出现次数最多的一个哈希值。
        可以采用以上两种方法中的任意一种，具体选择根据数据集的特点以及实现难度和效率来决定。


#### TCP and UDP


    OSI 和 TCP/UDP 都是网络通信的协议范式，但它们的角色和定位不同。

OSI 模型是一种概念性的框架，用来描述网络通信的各个层次，从而使不同的协议能够在特定层次上相互协作。
而 `TCP/UDP` 则是 OSI 模型中两个很重要的协议，它们分别负责 OSI 模型的`传输层`。


- `TCP (Transmission Control Protocol) `是 OSI 模型中第四层（传输层）的协议之一。

TCP 提供了可靠的数据传输和流量控制服务，在数据传输过程中保证数据的完整性、可靠性和有序性。

TCP 协议的特点是面向连接、有序、可靠。它适用于对网络延迟要求较高，对数据准确性要求较高的应用。

- `UDP (User Datagram Protocol) `是 OSI 模型中第四层（传输层）的协议之一。

UDP 与 TCP 不同之处在于它是一种无连接协议，通信双方在传输数据之前不需要建立连接。

UDP 在数据传输过程中不保证数据的完整性、可靠性和有序性。UDP 协议的特点是无连接、不可靠、简单、高效。
它适用于对网络延迟要求较低，对数据准确性要求不高的应用。

    
    在实际网络通信中，TCP 和 UDP 都有各自的应用场景。
    
    例如，在文件传输、电子邮件等应用场景中，TCP 协议的可靠性和保证数据完整性是非常重要的。
    而在视频流传输、音频流传输、在线游戏等应用场景中，UDP 由于传输效率高，可以更好地满足实时性要求。



- TCP 的`三次握手`和`四次挥手`

TCP 的`三次握手`和`四次挥手` 是 TCP 协议用于建立和关闭连接时的具体过程。
简单来说，三次握手是客户端和服务器建立连接，四次挥手是关闭连接。


三次握手是指：
    
    客户端向服务器发送 SYN （同步请求）包。
    服务器收到 SYN 包后，向客户端发送 SYN/ACK（同步应答）包。
    客户端收到 SYN/ACK 包后，向服务器发送 ACK（确认）包。

这时，TCP 连接建立成功。

四次挥手是指：
    
    客户端发送 FIN （结束）包。
    服务器收到 FIN 包后，向客户端发送 ACK 包，表明已收到关闭请求。
    服务器处理完客户端的数据后，发送 FIN 包给客户端，表示数据处理完成，可以关闭连接。
    客户端收到 FIN 包后，向服务器发送 ACK 包，表明自己也准备关闭连接。
这时，TCP 连接关闭完成。

需要注意的是，TCP 连接的建立和关闭都是需要经过三次握手和四次挥手的过程，这样可以保证连接的可靠性和完整性。
同时，在实际应用中还需要考虑网络延迟、丢包等因素，以确保 TCP 连接的稳定性和高效性。


![](https://raw.githubusercontent.com/landybird/landybird.github.io/master/assets/images/tcp34.png)



#### 常见的使用`UDP协议`的应用


`UDP（User Datagram Protocol`）是一种`面向无连接`的传输层协议，它主要用于传输不需要可靠性保证的短消息或实时数据，如音频和视频。

以下是常见使用UDP协议的应用：

    DNS (Domain Name System)：

        DNS 是一种域名系统，其主要作用是通过域名将网站的 IP 地址解析出来，使用户能够通过友好的域名访问网站。
        DNS 请求和响应都使用UDP协议，因为其具有低延迟和快速传输的特点，对于DNS解析来说特别适合。

    实时游戏：

        UDP 可以提供低延迟和高速的网络传输，使得实时游戏的玩家可以在网络游戏中及时地接收和传输数据。
        例如，一些大型多人在线游戏（MMO）就使用UDP协议来快速同步玩家的数据和位置。
    
    VoIP（Voice over Internet Protocol）：

        VoIP 技术使用 UDP 协议来传输语音数据包，使得用户可以通过网络进行语音和视频通信。
        由于 UDP 协议不需要保证数据包的可靠性，因此在使用 VoIP 时可能会出现少量的数据包丢失或抖动，但是这种情况不会对用户造成太大影响。
    
    IoT（Internet of Things）：

        IoT 设备通常需要进行快速的消息传输，因此 UDP 协议非常适合用于传输 IoT 设备的状态和数据包。
        使用UDP协议可以加快速度，降低延迟，提高设备响应速度。

    实时视频流：UDP协议广泛应用于视频流的传输，例如实时直播和视频会议等。

        UDP 的快速传输和低延迟使得实时视频流的传输更加顺畅和实时。
        但UDP协议也存在数据包丢失和抖动的问题，需要应用程序进行处理和优化。


#### MVCC 机制

`MVCC（多版本并发控制` 是一种高效并发控制协议，通过`为每个事务的读操作提供一个独立的版本号`，实现了多个事务之间的隔离性，避免了传统的锁机制可能带来的死锁和阻塞。

- 导致`RC`、`RR`这两种隔离级别的`快照读` 不同原因:


        RC级别下，每一次的快照读都会重新生产 Read View 
        
        RR级别下，则会沿用 第一次快照读生成的 Read View。

- `RR 模式`下 `update delete `为什么触发`当前读`



        在 MySQL 中，RR （Repeatable Read）隔离级别下，update delete 操作会触发当前读，

            这是因为 RR 隔离级别下，事务在进行查询时会对读取的数据加上 共享锁，以保证查询结果的一致性。
            但是，当执行 update delete 操作时，需要对数据加上  排他锁（exclusive lock），以防止其他事务同时对同一行数据进行修改或删除操作，而排他锁不能与共享锁同时存在，因此当前读会被触发。
        
        具体来说，当一个事务在 RR 隔离级别下执行 SELECT 操作时，MySQL 会为结果集中的所有行加上共享锁。
        如果这个事务在执行 SELECT 操作时发现需要修改或删除某个行，那么它会尝试将该行的共享锁升级为排他锁，这一过程就会触发当前读。
        
        需要注意的是，在 RR 隔离级别下进行 update delete 操作触发当前读的问题并不意味着 RR 隔离级别是不合适的，事实上，RR 隔离级别在保障数据的一致性方面仍然是非常有价值的。
        只要在使用 RR 隔离级别时合理使用锁机制，就可以避免出现当前读引起的问题。

- `MVCC 机制`

MVCC 基本思想是：
    
    每行数据保存多个版本，而不仅仅是当前版本。

    当某一事务需要对某行记录进行操作时，系统会取出该行的最新版本，然后进行操作，同时生成一个新版本，更新该行记录。

每个版本都有一个唯一的时间戳，可以`通过时间戳判断该数据是否可见`。
如果当前事务的时间戳小于该行数据版本的时间戳，那么该行数据对于当前事务来说是不可见的。


在 MySQL 中，RR （Repeatable Read）隔离级别下，update delete 操作会触发当前读，这是因为 RR 隔离级别下，事务在进行查询时会对读取的数据加上共享锁，以保证查询结果的一致性。但是，当执行 update delete 操作时，需要对数据加上排他锁（exclusive lock），以防止其他事务同时对同一行数据进行修改或删除操作，而排他锁不能与共享锁同时存在，因此当前读会被触发。

具体来说，当一个事务在 RR 隔离级别下执行 SELECT 操作时，MySQL 会为结果集中的所有行加上共享锁。如果这个事务在执行 SELECT 操作时发现需要修改或删除某个行，那么它会尝试将该行的共享锁升级为排他锁，这一过程就会触发当前读。

需要注意的是，在 RR 隔离级别下进行 update delete 操作触发当前读的问题并不意味着 RR 隔离级别是不合适的，事实上，RR 隔离级别在保障数据的一致性方面仍然是非常有价值的。只要在使用 RR 隔离级别时合理使用锁机制，就可以避免出现当前读引起的问题。

对于已经提交的事务，其生成的版本可以一直保存；对于未提交的事务，则可以在事务回滚时撤销其生成的版本。

    MVCC 实现增删查改操作

        Insert：

            当执行 Insert 操作时，会为该新记录生成一个版本号，同时该版本也成为该行数据的最新版本。如果数据需要更新后再次插入，会生成另一个版本号。
        
        Delete：

            当执行 Delete 操作时，InnoDB 不会立即删除该行记录，而是将其当前版本的删除标志位设置为 true，并插入一条新版本，版本号比原始版本号大 1，同时修改该行记录的删除标志位为 false。
            这么做是为了避免在并发环境中的读操作读到错误数据。
        
        Update：
            
            InnoDB 也不会立即更新该行记录，而是将其当前版本的删除标志位设置为 true，并插入一条新版本，版本号比原始版本号大 1，然后将该新版本的记录值修改为更新后的值。
            这么做是为了避免同样的原因，避免在并发环境中的读操作读到错误数据。
        
        Select：
            
            当执行 Select 操作时，InnoDB 会先计算出当前事务的版本信息，然后读取该版本的记录值，如果发现该行的版本号比当前事务的版本号小，则视为该行数据已经过期，无法读取，返回一个 null。

以上就是 MVCC 的机制以及增删查改操作的实现方式。

MVCC 可以在高并发环境下提高数据库的并发性能，避免了传统锁机制可能带来的死锁和阻塞。
但同时，MVCC 也带来了额外的存储和计算开销，需要根据具体业务需求对其进行调整。




#### I/O多路复用（IO multiplexing）

`I/O多路复用（IO multiplexing` 是一种用于管理多个 `socket` 连接的机制，
它允许`单线程`在没有阻塞的情况下处理多个连接，提高了程序的并发性和效率。


在 Linux 中，使用 `select` 函数来实现` I/O` 多路复用。

    在使用 select 函数时，需要将需要监控的 文件描述符（即套接字）放入一个 fd_set 集合中，然后传入 select 函数中进行监控。
    fd_set 集合中的大小是固定的，默认是 1024，这意味着一次最多可以监控 1024 个文件描述符。

那么为什么 select 描述符的限制是 `1024 `

    这是因为在早期的系统中，fd_set 采用的是一个 32 位的数组来表示文件描述符是否可读。
    32 位表示的最大十进制数是 2^32-1，即 4294967295，也就是说一个 fd_set 最多可以表示 4294967296 个描述符，
    这远远超过了实际需要的数量。为了节约空间，选择了一个比较小的数值 1024。

    此外，更大的 fd_set 数组会占用更多的资源，而且 select 函数的效率也会受到影响，因此采用 1024 这一相对较小的数值是一种平衡的做法。

随着计算机的发展，现在的系统一般采用 `poll` 或 `epoll` 等新的机制来实现 `I/O 多路复用`，可以`支持更多的文件描述符`


#### `TCP滑动窗口`


`TCP滑动窗口` 是一种流量控制的机制，用于控制发送方发送数据的速率，避免网络拥塞和丢包。
它采用了一个滑动窗口的概念，同时限制了发送方和接收方的数据量。


具体原理如下：

    发送方和接收方在建立连接时，会协商一个窗口大小（即滑动窗口的大小）。
    
    发送方将待发送的数据分成若干个数据段，每个数据段的大小不能超过窗口大小，发送到接收方。
    
    接收方收到数据后，会将其放置在接收缓冲区中，并发送一个确认消息（ACK）给发送方，通知它已经成功接收了数据。
    
    发送方收到接收方的ACK后，会将窗口向右滑动一个位置，即将窗口中已经确认的数据删除，并发送新的数据。
    
    如果发送方没有接收到接收方的ACK，说明接收方并没有成功接收到数据，发送方会不断重发该数据，直到接收到ACK为止。
    
    通过这种方式，利用滑动窗口的机制，TCP可以自适应地控制数据的传输速率，避免网络拥塞和丢包，从而保证数据传输的可靠性和稳定性。




#### metaclass 在 django 中的应用 

    除了django中的ORM系统外，metaclass在Django REST framework（DRF）中也有广泛的应用。
    
    在DRF中，metaclass主要用于实现序列化器（Serializer）类的自动化行为。

        序列化器是DRF中很重要的一个概念，用来帮助我们将模型转化为JSON或其他格式的数据，或将JSON数据转化为模型实例。
    
        通过定义metaclass，DRF的Serializer类可以自动生成序列化和反序列化的功能，例如自动根据模型的字段生成序列化器的字段、自动根据模型的关系生成关联字段等。
    
    此外，在DRF中，metaclass还用于实现视图集（Viewset）类的自动化行为。

        视图集是DRF中用来处理HTTP请求的概念，与Django的视图函数类似。通过metaclass自动生成视图中的各个方法，包括get、post、put等HTTP方法的处理方式，
        从而使得实现RESTful API更加简洁方便。
    
    总的来说，metaclass在Django和DRF中都是非常重要的概念，用于实现自动化行为，减少重复的编码工作，提升代码复用程度和开发效率。


#### `list、tuple、dict`底层，`set去重原理`
 

    list底层是基于 数组 实现的，可以通过索引访问元素，可变类型，支持操作包括增删改查等。
    
    tuple底层同样是基于 数组 实现的，不同于list的是，tuple元素不可变，因此在当作不可变的常量表达式使用时，会比list更加高效。
    
    dict底层是基于 哈希表 实现的，支持按照键值对进行增删改查等操作，其中哈希表的实现保证了查找、插入等操作的平均时间复杂度为O(1)。

    set底层同样是基于 哈希表 实现的，其实现方式和dict类似，但是set中只保存了键值而没有对应的值，因此使用set可以很方便地实现去重操作。

        当使用set进行去重时，具体的原理是将需要去重的元素作为set的key来进行存储，重复的元素会被自动去除，而不需要像使用list一样进行手动去重操作。

需要注意的是，在使用哈希表实现的容器中，哈希函数的设计和实现会影响到容器的性能和使用效果。
哈希函数需要将不同的键值映射到尽量不同的散列桶中，避免哈希冲突。
如果哈希函数设计得不好，会导致哈希冲突过多，从而降低容器的效率。


